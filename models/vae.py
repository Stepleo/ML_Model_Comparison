import torch
import torch.nn as nn
from torch.nn import functional as F
from .layers import MLPEncoder, MLPDecoder
from .unet import UNet


class VAE(nn.Module):
    """
    Variational Autoencoder (VAE) with support for latent space classification.
    """
    def __init__(
        self,
        input_dim: int,
        hidden_dim: int,
        latent_dim: int,
        num_layers_encoder: int = 2,
        num_layers_decoder: int = 3,
        beta: float = 0.05,
        classification_mode: bool = False
    ):
        super(VAE, self).__init__()
        self.encoder = MLPEncoder(input_dim, hidden_dim, latent_dim, num_layers_encoder)
        self.decoder = MLPDecoder(latent_dim, hidden_dim, input_dim, num_layers_decoder)
        self.beta = beta  # KL importance parameter
        self.classification_mode = classification_mode

        # Classification head
        self.svm_layer = nn.Linear(latent_dim, 2)  # Assuming binary classification

    def reparameterize(self, mu: torch.Tensor, log_var: torch.Tensor) -> torch.Tensor:
        """Reparameterization trick: z = eps * std + mu."""
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return eps * std + mu

    def forward(self, x: torch.Tensor):
        """
        Full forward pass through the VAE. 
        If classification_mode is True, outputs the latent space class prediction.
        """
        batch_size = x.size(0)
        x_flat = x.view(batch_size, -1)  # Flatten for linear layers
        mu, log_var = self.encoder(x_flat)
        z = self.reparameterize(mu, log_var)

        if self.classification_mode:
            return self.svm_layer(z)  # Output class logits

        x_hat = self.decoder(z).view(x.size())  # Reshape back to input dimensions
        return x_hat, x, mu, log_var

    def loss_function(
        self, x: torch.Tensor, x_hat: torch.Tensor, mu: torch.Tensor, log_var: torch.Tensor
    ):
        """Computes the VAE loss (reconstruction + KL divergence)."""
        recon_loss = F.mse_loss(x_hat, x, reduction='sum')
        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())
        total_loss = recon_loss + self.beta * kl_loss
        return {
            "loss": total_loss,
            "Reconstruction_Loss": recon_loss,
            "KLD": kl_loss
        }

    def sample(self, num_samples: int, image_size: int = 64, device: torch.device = "cuda"):
        """Samples from the latent space and decodes to generate data."""
        z = torch.randn(num_samples, self.encoder.mu.out_features).to(device)
        samples = self.decoder(z).view(torch.Size([num_samples, image_size, image_size]))
        return samples

    def generate(self, x: torch.Tensor):
        """Given input x, returns the reconstructed image."""
        return self.forward(x)[0]


class SVMLoss(nn.Module):
    def __init__(self):
        super(SVMLoss, self).__init__()

    def forward(self, predictions, targets):
        """
        SVM loss: max(0, 1 - y * f), where y is the target (+1 or -1)
        and f is the raw prediction (logit).
        """
        # Convert targets from {0, 1} to {-1, 1}
        targets = 2 * targets - 1  # Converts 0 to -1 and 1 remains 1

        # Calculate hinge loss
        loss = torch.mean(torch.clamp(1 - predictions.t() * targets, min=0))
        return loss
    

# Does not work
class VAE_conv(UNet):
    """
    Inherits from the UNet to leverage the feature extraction and
    the image reconstruction from feature maps.
    After using the inherited encoder we get mu and sigma for q_phi.
    We then use the reparametrization trick to generate a sample z.
    z goes through a linear layer then is resized to be decoded into an image.
    ELBO maximization can be done by maximizing the log likelihood of the output
    of the decoder through a MSE minimization and the KL divergence is explicit thanks to the reparametrization.
    """
    def __init__(self, resnet, beta=0.005, classification_mode=False):
        super(VAE_conv, self).__init__(resnet.input_img_size, resnet)
        # Setup for the reparametrization trick
        self.fc_mu = nn.Linear(resnet.final_dim * resnet.final_dim, 8)
        self.fc_var = nn.Linear(resnet.final_dim * resnet.final_dim, 8)
        # self.fc_mu = nn.Conv2d(in_channels=512, out_channels=8, kernel_size=7)   
        # self.fc_var = nn.Conv2d(in_channels=512, out_channels=8, kernel_size=7)
        # Handles the sample generated by the reparametrization trick
        self.decoder_input = nn.ConvTranspose2d(in_channels=8, out_channels=512, kernel_size=resnet.final_dim)   
        # Head for generating an image
        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)
        # KL importance parameter
        self.beta = beta
        # Whether to use the VAE for classification or image generation
        self.classification_mode = classification_mode
        # Classification head
        self.svm_layer = nn.Linear(8, 2)


    def encode(self, input):
        """
        Encodes the data and generate mean and logvar.
        """
        encoded, _ = self.encoder(input)
        encoded_mean = encoded.mean(dim=1, keepdim=True)
        encoded_flatten = torch.flatten(encoded_mean, 1)

        # Split the result into mean and logvar 
        mu = self.fc_mu(encoded_flatten)
        log_var = self.fc_var(encoded_flatten)

        return [mu, log_var]
    
    def decode(self, z):
        """
        Gets output image from latent space sample.
        """
        z = z.unsqueeze(-1).unsqueeze(-1)
        sample = self.decoder_input(z)
        r_512_1 = self.d2(sample)
        r_512_2 = self.d2(r_512_1)
        r_256 = self.d3(r_512_2)
        r_128 = self.d4(r_256)
        r_64 = self.d5(r_128)
        out = self.outputs(r_64)
        return out

    def get_class(self, z):
        """
        Gets output image class from latent space sample using SVM.
        It is just a linear layer but you have to make sure the weights
        are trained using the SVMLoss that ensures margin maximization.
        """
        out_class = self.svm_layer(z)
        return out_class

    def reparameterize(self, mu, log_var):
        """
        Reparameterization trick to sample from N(mu, var) from
        N(0,1).
        """
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return eps * std + mu

    def forward(self, input):
        """
        Pass the input through the encoder and decoder.
        Returns the latent space parameters for loss computation.
        """
        mu, log_var = self.encode(input)
        z = self.reparameterize(mu, log_var)
        if self.classification_mode:
            return self.get_class(z)
        return  [self.decode(z), input, mu, log_var]

    def loss_function(self, input, output, mu, log_var):
        """
        Computes the VAE loss function.
        batch_weight * KL + MSE
        """
        kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())

        recons_loss = F.mse_loss(output, input)

        loss = self.beta * kld_loss + recons_loss
        return {'loss': loss, 'Reconstruction_Loss':recons_loss, 'KLD':-kld_loss}

    def sample(self, num_samples, device="cuda"):
        """
        Samples from the latent space and return the corresponding
        image.
        """
        z = torch.randn(num_samples, 8)

        z = z.to(device)

        samples = self.decode(z)
        return samples

    def generate(self, x):
        """
        Given an input image x, returns the reconstructed image.
        """
        return self.forward(x)[0]

    