import torch
import torch.nn as nn
from torch.nn import functional as F
from .unet import UNet

class VAE(UNet):
    """
    Inherits from the UNet to leverage the feature extraction and
    the image reconstruction from feature maps.
    After using the inherited encoder we get mu and sigma for q_phi.
    We then use the reparametrization trick to generate a sample z.
    z goes through a linear layer then is resized to be decoded into an image.
    ELBO maximization can be done by maximizing the log likelihood of the output
    of the decoder through a MSE minimization and the KL divergence is explicit thanks to the reparametrization.
    """
    def __init__(self, resnet, beta=0.005, classification_mode=False):
        super(VAE, self).__init__(resnet)
        # Setup for the reparametrization trick
        self.fc_mu = nn.Linear(resnet.final_dim * resnet.final_dim, 8)
        self.fc_var = nn.Linear(resnet.final_dim * resnet.final_dim, 8)
        # self.fc_mu = nn.Conv2d(in_channels=512, out_channels=8, kernel_size=7)   
        # self.fc_var = nn.Conv2d(in_channels=512, out_channels=8, kernel_size=7)
        # Handles the sample generated by the reparametrization trick
        self.decoder_input = nn.ConvTranspose2d(in_channels=8, out_channels=512, kernel_size=resnet.final_dim)   
        # Head for generating an image
        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)
        # KL importance parameter
        self.beta = beta
        # Whether to use the VAE for classification or image generation
        self.classification_mode = classification_mode
        # Classification head
        self.svm_layer = nn.Linear(8, 2)


    def encode(self, input):
        """
        Encodes the data and generate mean and logvar.
        """
        encoded, _ = self.encoder(input)
        encoded_mean = encoded.mean(dim=1, keepdim=True)
        encoded_flatten = torch.flatten(encoded_mean, 1)

        # Split the result into mean and logvar 
        mu = self.fc_mu(encoded_flatten)
        log_var = self.fc_var(encoded_flatten)

        return [mu, log_var]
    
    def decode(self, z):
        """
        Gets output image from latent space sample.
        """
        z = z.unsqueeze(-1).unsqueeze(-1)
        sample = self.decoder_input(z)
        r_512_1 = self.d2(sample)
        r_512_2 = self.d2(r_512_1)
        r_256 = self.d3(r_512_2)
        r_128 = self.d4(r_256)
        r_64 = self.d5(r_128)
        out = self.outputs(r_64)
        return out

    def get_class(self, z):
        """
        Gets output image class from latent space sample using SVM.
        It is just a linear layer but you have to make sure the weights
        are trained using the SVMLoss that ensures margin maximization.
        """
        out_class = self.svm_layer(z)
        return out_class

    def reparameterize(self, mu, log_var):
        """
        Reparameterization trick to sample from N(mu, var) from
        N(0,1).
        """
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return eps * std + mu

    def forward(self, input):
        """
        Pass the input through the encoder and decoder.
        Returns the latent space parameters for loss computation.
        """
        mu, log_var = self.encode(input)
        z = self.reparameterize(mu, log_var)
        if self.classification_mode:
            return self.get_class(z)
        return  [self.decode(z), input, mu, log_var]

    def loss_function(self, input, output, mu, log_var):
        """
        Computes the VAE loss function.
        batch_weight * KL + MSE
        """
        kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())

        recons_loss = F.mse_loss(output, input)

        loss = self.beta * kld_loss + recons_loss
        return {'loss': loss, 'Reconstruction_Loss':recons_loss, 'KLD':-kld_loss}

    def sample(self, num_samples, device="cuda"):
        """
        Samples from the latent space and return the corresponding
        image.
        """
        z = torch.randn(num_samples, 8)

        z = z.to(device)

        samples = self.decode(z)
        return samples

    def generate(self, x):
        """
        Given an input image x, returns the reconstructed image.
        """
        return self.forward(x)[0]



class SVMLoss(nn.Module):
    def __init__(self):
        super(SVMLoss, self).__init__()

    def forward(self, predictions, targets):
        return torch.sum(torch.clamp(1 - predictions.t()*targets, min=0))/predictions.size()[0]
    