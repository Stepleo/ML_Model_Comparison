import torch
import torch.nn as nn
from torch.nn import functional as F
from .unet import UNet

class VAE(UNet):
    """
    Inherits from the UNet to leverage the feature extraction and
    the image reconstruction from feature maps.
    After using the inherited encoder we get mu and sigma for q_phi.
    We then use the reparametrization trick to generate a sample z.
    z goes through a linear layer then is resized to be decoded into an image.
    ELBO maximization can be done by maximizing the log likelihood of the output
    of the decoder through a MSE minimization and the KL divergence is explicit thanks to the reparametrization.
    """
    def __init__(self, resnet, beta=0.005):
        super(VAE, self).__init__(resnet)
        # Setup for the reparametrization trick
        self.fc_mu = nn.Linear(512 * 7 * 7, 8)
        self.fc_var = nn.Linear(512 * 7 * 7, 8)
        # Handles the sample generated by the reparametrization trick
        self.decoder_input = nn.Linear(8, 512 * 7 * 7)
        # Head for generating an image
        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)
        # KL importance parameter
        self.beta = beta

    def encode(self, input):
        """
        Encodes the data and generate mean and logvar.
        """
        encoded, _ = self.encoder(input)
        encoded_flatten = torch.flatten(encoded, 1)

        # Split the result into mean and logvar 
        mu = self.fc_mu(encoded_flatten)
        log_var = self.fc_var(encoded_flatten)

        return [mu, log_var]
    
    def decode(self, z):
        """
        Gets output image from latent space sample.
        """
        sample = self.decoder_input(z)
        result = sample.view(-1, 512, 7, 7)
        r_512_1 = self.d2(result)
        r_512_2 = self.d2(r_512_1)
        r_256 = self.d3(r_512_2)
        r_128 = self.d4(r_256)
        r_64 = self.d5(r_128)
        out = self.outputs(r_64)
        return out

    def reparameterize(self, mu, log_var):
        """
        Reparameterization trick to sample from N(mu, var) from
        N(0,1).
        """
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return eps * std + mu

    def forward(self, input):
        """
        Pass the input through the encoder and decoder.
        Returns the latent space parameters for loss computation.
        """
        mu, log_var = self.encode(input)
        z = self.reparameterize(mu, log_var)
        return  [self.decode(z), input, mu, log_var]

    def loss_function(self, input, output, mu, log_var):
        """
        Computes the VAE loss function.
        batch_weight * KL + MSE
        """
        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - torch.clip(log_var.exp(), min=1e-5), dim = 1), dim = 0)

        recons_loss = F.mse_loss(output, input)

        loss = self.beta * kld_loss + recons_loss
        return {'loss': loss, 'Reconstruction_Loss':recons_loss, 'KLD':-kld_loss}

    def sample(self, num_samples, device="cuda"):
        """
        Samples from the latent space and return the corresponding
        image.
        """
        z = torch.randn(num_samples, 8)

        z = z.to(device)

        samples = self.decode(z)
        return samples

    def generate(self, x):
        """
        Given an input image x, returns the reconstructed image.
        """
        return self.forward(x)[0]
